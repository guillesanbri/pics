I"c<hr />

<p>This post will cover some of the features of a Virtal Reality DICOM file viewer, implemented in Unity3D. It uses VRTK4 as a base for the VR part and EvilDICOM to manage the DICOM part of things.</p>

<div style="position:relative; padding-bottom:calc(56.25% + 44px)"><iframe src="https://gfycat.com/ifr/FirsthandEvergreenHarpyeagle" frameborder="0" scrolling="no" width="100%" height="100%" style="position:absolute;top:0;left:0;" allowfullscreen=""></iframe></div>
<p> <a href="https://gfycat.com/firsthandevergreenharpyeagle">via Gfycat</a></p>

<hr />

<h1 id="terms--what-is-dicom">Terms // What is DICOM</h1>

<ul>
  <li>DICOM: DICOM is the standard for the communication and management of medical imaging information and related data. This means that DICOM files store much more than pixel data, they store patient info, clinical trial info, etc. This post will focus on the file type, more precisly, on Computed Tomography scans and Magnetic Resonance imaging, but keep in mind that DICOM is a bigger standard that covers a lot of thing.</li>
  <li></li>
</ul>

<div style="position:relative; padding-bottom:calc(56.25% + 44px)"><iframe src="https://gfycat.com/ifr/UnlawfulCrazyGourami" frameborder="0" scrolling="no" width="100%" height="100%" style="position:absolute;top:0;left:0;" allowfullscreen=""></iframe></div>
<p> <a href="https://gfycat.com/unlawfulcrazygourami">via Gfycat</a></p>

<div style="position:relative; padding-bottom:calc(56.25% + 44px)"><iframe src="https://gfycat.com/ifr/SlimyBlandCowbird" frameborder="0" scrolling="no" width="100%" height="100%" style="position:absolute;top:0;left:0;" allowfullscreen=""></iframe></div>
<p> <a href="https://gfycat.com/slimyblandcowbird">via Gfycat</a></p>

<div style="position:relative; padding-bottom:calc(56.25% + 44px)"><iframe src="https://gfycat.com/ifr/WarlikeHarmlessBorzoi" frameborder="0" scrolling="no" width="100%" height="100%" style="position:absolute;top:0;left:0;" allowfullscreen=""></iframe></div>
<p> <a href="https://gfycat.com/warlikeharmlessborzoi">via Gfycat</a></p>

<p>If you just want to read how to do the unity integration, jump to <a href="#UnityIntegration">Unity Integration</a></p>

<hr />

<h1 id="why-dicom">Why DICOM?</h1>

<p>It would be possible to try to reconstruct a 3D visualization of the scan from, let’s say, a bunch of PNG images that represent each of the slices taken during the procedure. This would result in a poor result, since we wouldn’t have key information such as the space between each slice. DICOM files keep all the information we need tightly integrated.</p>

<p>Furthermore, DICOM is used in <em>almost</em> every hospital on earth and every system that interacts with medical imaging information of any kind works with it.</p>

<p>Developing a medical application that complies with DICOM ensures interoperability with different systems from different manufacturers.</p>

<hr />

<h1 id="solutions">Solutions</h1>

<p>There are a few options to track the headset in space, some of them (the most used ones) are:</p>

<table>
  <thead>
    <tr>
      <th>  <strong>Devices</strong>   </th>
      <th style="text-align: center">   <strong>Pose</strong>   </th>
      <th style="text-align: center">  <strong>Inside-out tracking</strong>  </th>
      <th style="text-align: center">  <strong>Depth</strong>  </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Intel Realsense T265</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">No*</td>
    </tr>
    <tr>
      <td>Occipital Structure Core</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">Yes</td>
    </tr>
    <tr>
      <td>Vive tracker</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">No**</td>
      <td style="text-align: center">No</td>
    </tr>
  </tbody>
</table>

<p>*While not oficially supported, the <a href="https://www.intelrealsense.com/tracking-camera-t265/">Intel page</a> states that it is possible to compute a suboptimal dense depth. This is left as an exercise for the reader.</p>

<p>**To use a Vive tracker, you must have a Lighthouse system.</p>

<p>I decided to use an Intel Realsense T265 device, mainly because of it’s price and my needs, so that is what we will be integrating in Unity next.</p>

<hr />

<h1 id="unity-integration"><a name="UnityIntegration"></a>Unity Integration</h1>

<p>The first thing you want to do is go to the <a href="https://github.com/IntelRealSense/librealsense/tree/master/wrappers/unity">Intel Realsense Unity Wrapper github page</a> and then download the <a href="https://github.com/IntelRealSense/librealsense/releases/download/v2.20.0/realsense.unitypackage">realsense.unitypackage</a>.</p>

<p>Once you have downloaded it, drag and drop it into your <a href="https://github.com/leapmotion/ProjectNorthStar/tree/master/Software">NorthStar Unity project</a>.</p>

<p>Your hierarchy should look like this:</p>

<p><img src="./../images/NS-software-1/base_hierarchy.jpg" alt="Clean project" /></p>

<p>Navigate through your project folders <strong>Assets -&gt; RealSenseSDK2.0 -&gt; Prefabs</strong> and drag and drop the <strong>RsDevice</strong> prefab in your hierarchy.</p>

<p><img src="./../images/NS-software-1/RsDevice.jpg" alt="RsDevice prefab" /></p>

<p>Once you have the RsDevice gameobject in your hierarchy, click it and look at the inspector, it should have three profiles by default:</p>

<p><img src="./../images/NS-software-1/RsDevice3Profiles.jpg" alt="RsDevice three profiles" /></p>

<p>Change it to one, then, set the <strong>Stream</strong> variable to <strong>Pose</strong>,the <strong>Format</strong> to <strong>Six DOF</strong> and <strong>Framerate</strong>,<strong>Stream Index</strong>,<strong>Width</strong> and <strong>Height</strong> to zero.</p>

<p><img src="./../images/NS-software-1/RsDevice1Profile.jpg" alt="RsDevice pose profile" /></p>

<p>Now, navigate to <strong>ARCameraRig -&gt; Leap Odometry Origin</strong> in your hierarchy, click <strong>Add Component</strong> and look for <strong>Rs Pose Stream Transformer</strong></p>

<p><img src="./../images/NS-software-1/AddComponent.jpg" alt="Add Pose Stream to Leap Odometry" /></p>

<p>Drag and drop your <strong>RsDevice</strong> in the <strong>Source</strong> variable of the <strong>Rs Pose Stream Transformer</strong> you just added.</p>

<p><img src="./../images/NS-software-1/SourceVariable.jpg" alt="RsDevice to source variable" /></p>

<p>Now you can add a cube to your scene, scale it down a bit, place it in front of the headset and hit play, and you should be able to move around the cube!</p>

<hr />

<p>Related links</p>
<ul>
  <li><a href="https://www.intelrealsense.com/">Intel Realsense</a></li>
  <li><a href="https://structure.io/structure-core">Occipital Structure Core</a></li>
  <li><a href="https://www.vive.com/us/vive-tracker/">Vive trackers</a></li>
  <li><a href="https://github.com/leapmotion/ProjectNorthStar/tree/master/Software">Github repo (Software)</a></li>
  <li><a href="https://discordapp.com/invite/ATPm9Fy">Discord server</a></li>
</ul>

<hr />
:ET